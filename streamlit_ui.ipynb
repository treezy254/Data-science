{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6bg1jVDdobzIEAvr5kcgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treezy254/Data-science/blob/main/streamlit_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXx5zszg57Ve",
        "outputId": "46369804-5430-4445-a93c-b6f2b84159a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning Ollama-Companion from git...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Clone the repository\n",
        "!git clone --branch Colab-installer https://github.com/treezy254/Ollama-Companion.git 2> /dev/null 1>&2\n",
        "print(\"Cloning Ollama-Companion from git...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install virtualenv\n",
        "!sudo apt install virtualenv 2> /dev/null 1>&2\n",
        "print(\"Installing some dependencies, please hold on...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c02Ar-Yq6KPh",
        "outputId": "9d10cb2d-1bac-4f31-825f-e06e73ebd5ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing some dependencies, please hold on...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert Windows line endings to Unix line endings in the install.sh script\n",
        "!sed -i 's/\\r//' /content/Ollama-Companion/install.sh 2> /dev/null 1>&2\n",
        "print(\"Converting line endings in install script...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6HGNZxf6LhF",
        "outputId": "63bf95ea-c02f-4f3e-adea-ef32ca27c8d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting line endings in install script...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make the script executable and run it\n",
        "!chmod +x /content/Ollama-Companion/install.sh 2> /dev/null 1>&2\n",
        "print(\"Running the installation script and compiling Llama.cpp...\")\n",
        "!/content/Ollama-Companion/install.sh 2> /dev/null 1>&2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahPxt2dX6UgM",
        "outputId": "a4570504-c478-4bb4-d5d6-0cace73b36f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running the installation script and compiling Llama.cpp...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Purge pip cache and clean up temporary files\n",
        "!pip cache purge 2> /dev/null 1>&2\n",
        "!find /tmp -type f -atime +1 -delete 2> /dev/null 1>&2\n",
        "!sudo apt-get clean 2> /dev/null 1>&2\n",
        "!sudo apt-get autoremove 2> /dev/null 1>&2\n",
        "print(\"Cleaning up and finalizing setup...\")\n",
        "print(\"Started all apps run the cell below if you want to restart\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3XiDckm6WFR",
        "outputId": "93dbf2fc-60f1-4d5f-a0db-d44adfbcf76d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning up and finalizing setup...\n",
            "Started all apps run the cell below if you want to restart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the application\n",
        "!python3 /content/Ollama-Companion/run_app.py\n",
        "print(\"Started all apps run the cell below if you want to restart\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpfiNW6m6XR1",
        "outputId": "2bdf3719-9abc-4317-b83d-939a9008801b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Cloudflare Tunnel...\n",
            "Starting Streamlit App...\n",
            "Starting Ollama...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "Tunnel URL: https://graphic-pink-command-colony.trycloudflare.com\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.233.136.58:8501\u001b[0m\n",
            "\u001b[0m\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.10/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1567, in _shutdown\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama-Companion/run_app.py\", line 39, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama-Companion/run_app.py\", line 35, in main\n",
            "    streamlit_thread.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    lock.acquire()\n",
            "KeyboardInterrupt: \n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Started all apps run the cell below if you want to restart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XGuc2pF6Xnq"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}