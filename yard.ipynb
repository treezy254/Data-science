{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkLd2xoiOmLEz5NiCbZ1Vh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treezy254/Data-science/blob/main/yard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCEuhIFMUItP"
      },
      "outputs": [],
      "source": [
        "!pip install promptflow promptflow-tools\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import textwrap\n",
        "from typing import Union\n",
        "import json\n",
        "\n",
        "import google.generativeai as genai\n",
        "import google.ai.generativelanguage as glm\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "from promptflow.tools.common import render_jinja_template\n",
        "from promptflow import tool\n",
        "\n",
        "sys.path.append('.')\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "RvjDWxaVVUJ8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "YYtGIWMRVWra",
        "outputId": "95230253-c29d-4f85-84ac-44e08080b2b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# goal\n",
        "def generate_goal(items: list = []) -> str:\n",
        "    \"\"\"\n",
        "    Generate a numbered list from given items based on the item_type.\n",
        "\n",
        "    Args:\n",
        "        items (list): A list of items to be numbered.\n",
        "\n",
        "    Returns:\n",
        "        str: The formatted numbered list.\n",
        "    \"\"\"\n",
        "    return \"\\n\".join(f\"{i + 1}. {item}\" for i, item in enumerate(items))\n",
        "\n",
        "goals = ['''Introduce 'Lord of the Rings' film trilogy including the film title,\n",
        "      release year, director, current age of the director, production company\n",
        "      and a brief summary of the film.''']\n"
      ],
      "metadata": {
        "id": "QDgBvBLsXTgH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompts"
      ],
      "metadata": {
        "id": "oXxtdg0oWESL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def system_prompt(name, role):\n",
        "    \"\"\"\n",
        "    Generates a prompt for a specific function using a Jinja2 template.\n",
        "    \"\"\"\n",
        "    from promptflow.tools.common import render_jinja_template\n",
        "\n",
        "    with open('system_prompt.jinja2') as file:\n",
        "        return render_jinja_template(prompt=file.read(), name=name, role=role)\n",
        "\n",
        "def user_prompt(goals):\n",
        "    \"\"\"\n",
        "    Generates a prompt for a specific function using a Jinja2 template.\n",
        "    \"\"\"\n",
        "    from promptflow.tools.common import render_jinja_template\n",
        "\n",
        "    with open('user_prompt.jinja2') as file:\n",
        "        return render_jinja_template(prompt=file.read(), goals=goals)\n",
        "\n",
        "def triggering_prompt():\n",
        "    \"\"\"\n",
        "    Generates a prompt for a specific function using a Jinja2 template.\n",
        "    \"\"\"\n",
        "    from promptflow.tools.common import render_jinja_template\n",
        "\n",
        "    with open('triggering_prompt.jinja2') as file:\n",
        "        return render_jinja_template(prompt=file.read())\n",
        "\n",
        "system_prompt = system_prompt('FilmTriviaGPT', 'an AI specialized in film trivia that provides accurate and up-to-dateinformation about movies, directors, actors, and more.')\n",
        "\n",
        "\n",
        "user_prompt = user_prompt(\"Introduce 'Lord of the Rings' film trilogy including the film title, release year, director, current age of the director, production company and a brief summary of the film.\")\n",
        "\n",
        "triggering_prompt = triggering_prompt()"
      ],
      "metadata": {
        "id": "VtacnxTcVe3g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "sUqp2nNCWGCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# python\n",
        "python_execution_tool = glm.Tool(\n",
        "     function_declarations=[\n",
        "        glm.FunctionDeclaration(\n",
        "            name='python',\n",
        "            description=\"Executes Python code.\",\n",
        "            parameters=glm.Schema(\n",
        "                type=glm.Type.OBJECT,\n",
        "                properties={\n",
        "                    'command': glm.Schema(type=glm.Type.STRING)\n",
        "                },\n",
        "                required=['command']\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# search\n",
        "search_execution_tool = glm.Tool(\n",
        "    function_declarations = [\n",
        "        glm.FunctionDeclaration(\n",
        "            name='search',\n",
        "            description=\"The action will search this entity name on Wikipedia and returns the first {count} sentences if it exists. If not, it will return some related entities to search next.\",\n",
        "            parameters=glm.Schema(\n",
        "                type=glm.Type.OBJECT,\n",
        "                properties={\n",
        "                    'entity': glm.Schema(type=glm.Type.STRING),\n",
        "                    'count': glm.Schema(type=glm.Type.NUMBER)\n",
        "                },\n",
        "                required=[\"entity\"],\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# finish\n",
        "finish_execution_tool = glm.Tool(\n",
        "    function_declarations = [\n",
        "      glm.FunctionDeclaration(\n",
        "        name=\"finish\",\n",
        "        description=\"\"\"use this to signal that you have finished all your goals and remember show your\n",
        "        results\"\"\",\n",
        "        parameters=glm.Schema(\n",
        "          type=glm.Type.OBJECT,\n",
        "          properties={\n",
        "            'response': glm.Schema(type=glm.Type.STRING),\n",
        "          },\n",
        "          required=[\"response\"]\n",
        "        )\n",
        "      ),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "\n",
        "my_execution_tools = glm.Tool(\n",
        "    function_declarations = [\n",
        "        glm.FunctionDeclaration(\n",
        "            name='python',\n",
        "            description=\"Executes Python code.\",\n",
        "            parameters=glm.Schema(\n",
        "                type=glm.Type.OBJECT,\n",
        "                properties={\n",
        "                    'command': glm.Schema(type=glm.Type.STRING)\n",
        "                },\n",
        "                required=['command']\n",
        "            )\n",
        "        ),\n",
        "\n",
        "        glm.FunctionDeclaration(\n",
        "            name='search',\n",
        "            description=\"The action will search this entity name on Wikipedia and returns the first 10 sentences if it exists. If not, it will return some related entities to search next.\",\n",
        "            parameters=glm.Schema(\n",
        "                type=glm.Type.OBJECT,\n",
        "                properties={\n",
        "                    'entity': glm.Schema(type=glm.Type.STRING),\n",
        "                    'count': glm.Schema(type=glm.Type.NUMBER)\n",
        "                },\n",
        "                required=[\"entity\"],\n",
        "            )\n",
        "        ),\n",
        "\n",
        "        glm.FunctionDeclaration(\n",
        "        name=\"finish\",\n",
        "        description=\"\"\"use this to signal that you have finished all your goals and remember show your\n",
        "        results\"\"\",\n",
        "        parameters=glm.Schema(\n",
        "          type=glm.Type.OBJECT,\n",
        "          properties={\n",
        "            'response': glm.Schema(type=glm.Type.STRING),\n",
        "          },\n",
        "          required=[\"response\"]\n",
        "        )\n",
        "      )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "4mUHm1UnV8w0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new generative model with the added tool\n",
        "tools=[search_execution_tool, finish_execution_tool]\n",
        "model_with_python_tool = genai.GenerativeModel('gemini-pro', tools=[my_execution_tools])\n",
        "chat_with_python_tool = model_with_python_tool.start_chat()\n",
        "\n",
        "# Send a message to execute Python code\n",
        "response = chat_with_python_tool.send_message(\"you have no task left\")"
      ],
      "metadata": {
        "id": "GbVyRyyybj10"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTLr1rKcb3_a",
        "outputId": "114a8375-5b9a-4a40-ddf2-74035c7e771a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[content {\n",
              "  parts {\n",
              "    function_call {\n",
              "      name: \"finish\"\n",
              "      args {\n",
              "        fields {\n",
              "          key: \"response\"\n",
              "          value {\n",
              "            string_value: \"I have no task left.\"\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "index: 0\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.protobuf.json_format import MessageToDict\n",
        "\n",
        "func_name = MessageToDict(response.candidates[0].content.parts[0]._pb)\n",
        "if 'functionCall' in func_name:\n",
        "  print('yes')\n",
        "\n",
        "else:\n",
        "  print('No')\n",
        "  print(func_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQHcGm2g-U-",
        "outputId": "dc4f560e-6a3f-47f4-a085-d1705a91696f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.protobuf.json_format import MessageToDict\n",
        "\n",
        "response_json = MessageToDict(response.candidates[0].content.parts[0].function_call._pb)\n",
        "\n",
        "print(response_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUrSzqtFb8sR",
        "outputId": "50d8633b-efed-4894-a074-7a5d415c62b6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'finish', 'args': {'response': 'I have no task left.'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "E7qfMRGOX81y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from typing import List\n",
        "import re\n",
        "import tiktoken\n",
        "import logging\n",
        "import sys\n",
        "import json\n",
        "\n",
        "FORMATTER = logging.Formatter(\n",
        "    fmt=\"[%(asctime)s] %(name)-8s %(levelname)-8s %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S %z\",\n",
        ")\n",
        "\n",
        "\n",
        "def get_logger(name: str, level=logging.INFO) -> logging.Logger:\n",
        "    logger = logging.Logger(name)\n",
        "    # log to sys.stdout for backward compatibility.\n",
        "    # TODO: May need to be removed in the future, after local/blob file stream are fully supported.\n",
        "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
        "    stdout_handler.setFormatter(FORMATTER)\n",
        "    logger.addHandler(stdout_handler)\n",
        "    logger.setLevel(level)\n",
        "    return logger\n",
        "\n",
        "\n",
        "def parse_reply(text: str):\n",
        "    try:\n",
        "        parsed = json.loads(text, strict=False)\n",
        "    except json.JSONDecodeError:\n",
        "        preprocessed_text = preprocess_json_input(text)\n",
        "        try:\n",
        "            parsed = json.loads(preprocessed_text, strict=False)\n",
        "        except Exception:\n",
        "            return {\"Error\": f\"Could not parse invalid json: {text}\"}\n",
        "    except TypeError:\n",
        "        return {\"Error\": f\"the JSON object must be str, bytes or bytearray not {type(text)}\"}\n",
        "    return parsed\n",
        "\n",
        "\n",
        "def count_message_tokens(\n",
        "    messages: List, model: str = \"gpt-3.5-turbo-0301\"\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Returns the number of tokens used by a list of messages.\n",
        "\n",
        "    Args:\n",
        "        messages (list): A list of messages, each of which is a dictionary\n",
        "            containing the role and content of the message.\n",
        "        model (str): The name of the model to use for tokenization.\n",
        "            Defaults to \"gpt-3.5-turbo-0301\".\n",
        "\n",
        "    Returns:\n",
        "        int: The number of tokens used by the list of messages.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        encoding = tiktoken.encoding_for_model(model)\n",
        "    except KeyError:\n",
        "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    if model == \"gpt-3.5-turbo\":\n",
        "        # !Note: gpt-3.5-turbo may change over time.\n",
        "        # Returning num tokens assuming gpt-3.5-turbo-0301.\")\n",
        "        return count_message_tokens(messages, model=\"gpt-3.5-turbo-0301\")\n",
        "    elif model == \"gpt-4\":\n",
        "        # !Note: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n",
        "        return count_message_tokens(messages, model=\"gpt-4-0314\")\n",
        "    elif model == \"gpt-3.5-turbo-0301\":\n",
        "        tokens_per_message = (\n",
        "            4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
        "        )\n",
        "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
        "    elif model == \"gpt-4-0314\":\n",
        "        tokens_per_message = 3\n",
        "        tokens_per_name = 1\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            f\"num_tokens_from_messages() is not implemented for model {model}.\\n\"\n",
        "            \" See https://github.com/openai/openai-python/blob/main/chatml.md for\"\n",
        "            \" information on how messages are converted to tokens.\"\n",
        "        )\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
        "    return num_tokens\n",
        "\n",
        "\n",
        "def count_string_tokens(string: str, model_name=\"gpt-3.5-turbo\") -> int:\n",
        "    \"\"\"\n",
        "    Returns the number of tokens in a text string.\n",
        "\n",
        "    Args:\n",
        "        string (str): The text string.\n",
        "        model_name (str): The name of the encoding to use. (e.g., \"gpt-3.5-turbo\")\n",
        "\n",
        "    Returns:\n",
        "        int: The number of tokens in the text string.\n",
        "    \"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model_name)\n",
        "    return len(encoding.encode(string))\n",
        "\n",
        "\n",
        "def create_chat_message(role, content, name=None):\n",
        "    \"\"\"\n",
        "    Create a chat message with the given role and content.\n",
        "\n",
        "    Args:\n",
        "    role (str): The role of the message sender, e.g., \"system\", \"user\", or \"assistant\".\n",
        "    content (str): The content of the message.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing the role and content of the message.\n",
        "    \"\"\"\n",
        "    if name is None:\n",
        "        return {\"role\": role, \"content\": content}\n",
        "    else:\n",
        "        return {\"role\": role, \"name\": name, \"content\": content}\n",
        "\n",
        "\n",
        "def generate_context(prompt, full_message_history, user_prompt, model=\"gpt-3.5-turbo\"):\n",
        "    current_context = [\n",
        "        create_chat_message(\"system\", prompt),\n",
        "        create_chat_message(\n",
        "            \"system\", f\"The current time and date is {time.strftime('%c')}\"\n",
        "        ),\n",
        "        create_chat_message(\"user\", user_prompt),\n",
        "    ]\n",
        "\n",
        "    # Add messages from the full message history until we reach the token limit\n",
        "    next_message_to_add_index = len(full_message_history) - 1\n",
        "    insertion_index = len(current_context)\n",
        "    # Count the currently used tokens\n",
        "    current_tokens_used = count_message_tokens(current_context, model)\n",
        "    return (\n",
        "        next_message_to_add_index,\n",
        "        current_tokens_used,\n",
        "        insertion_index,\n",
        "        current_context,\n",
        "    )\n",
        "\n",
        "\n",
        "def preprocess_json_input(input_str: str) -> str:\n",
        "    # Replace single backslashes with double backslashes, while leaving already escaped ones intact\n",
        "    corrected_str = re.sub(r'(?<!\\\\)\\\\(?![\"\\\\/bfnrt]|u[0-9a-fA-F]{4})', r\"\\\\\\\\\", input_str)\n",
        "    return corrected_str\n",
        "\n",
        "\n",
        "def construct_prompt(current_context):\n",
        "    update_current_context = []\n",
        "    for item in current_context:\n",
        "        role = item.get(\"role\", None)\n",
        "        content = item.get(\"content\", None)\n",
        "        name = item.get(\"name\", None)\n",
        "\n",
        "        if name is not None:\n",
        "            update_current_context.append(\":\\n\".join([role, \"name\", name]) + \"\\n\" + \":\\n\".join([\"content\", content]))\n",
        "        else:\n",
        "            update_current_context.append(\":\\n\".join([role, content]))\n",
        "    update_current_context = \"\\n\".join(update_current_context)\n",
        "    return update_current_context\n"
      ],
      "metadata": {
        "id": "Sy3Vai-4X8dB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent"
      ],
      "metadata": {
        "id": "a6PRllGWX1Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import google.ai.generativelanguage as glm\n",
        "\n",
        "\n",
        "from util import count_message_tokens, count_string_tokens, create_chat_message, generate_context, get_logger, \\\n",
        "    parse_reply, construct_prompt\n",
        "\n",
        "autogpt_logger = get_logger(\"autogpt_agent\")\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyBpGTci77tIs_SIUP-618cCbpg2JwYJ-Tk\")\n",
        "\n",
        "class AutoGPT:\n",
        "    def __init__(\n",
        "        self,\n",
        "        tools,\n",
        "        full_message_history,\n",
        "        functions,\n",
        "        system_prompt=None,\n",
        "        triggering_prompt=None,\n",
        "        user_prompt=None,\n",
        "        model_or_deployment_name=None\n",
        "    ):\n",
        "        self.tools = tools\n",
        "        self.full_message_history = full_message_history\n",
        "        self.functions = functions\n",
        "        self.system_prompt = system_prompt\n",
        "        self.model_or_deployment_name = model_or_deployment_name\n",
        "        self.triggering_prompt = triggering_prompt\n",
        "        self.user_prompt = user_prompt\n",
        "\n",
        "    def chat_with_ai(self, token_limit):\n",
        "        \"\"\"Interact with the OpenAI API, sending the prompt, message history and functions.\"\"\"\n",
        "\n",
        "        # Reserve 1000 tokens for the response\n",
        "        send_token_limit = token_limit - 1000\n",
        "        (\n",
        "            next_message_to_add_index,\n",
        "            current_tokens_used,\n",
        "            insertion_index,\n",
        "            current_context,\n",
        "        ) = generate_context(self.system_prompt, self.full_message_history, self.user_prompt)\n",
        "        # Account for user input (appended later)\n",
        "        current_tokens_used += count_message_tokens([create_chat_message(\"user\", self.triggering_prompt)])\n",
        "        current_tokens_used += 500  # Account for memory (appended later)\n",
        "        # Add Messages until the token limit is reached or there are no more messages to add.\n",
        "        while next_message_to_add_index >= 0:\n",
        "            message_to_add = self.full_message_history[next_message_to_add_index]\n",
        "\n",
        "            tokens_to_add = count_message_tokens([message_to_add])\n",
        "            if current_tokens_used + tokens_to_add > send_token_limit:\n",
        "                break\n",
        "\n",
        "            # Add the most recent message to the start of the current context, after the two system prompts.\n",
        "            current_context.insert(\n",
        "                insertion_index, self.full_message_history[next_message_to_add_index]\n",
        "            )\n",
        "\n",
        "            # Count the currently used tokens\n",
        "            current_tokens_used += tokens_to_add\n",
        "            # Move to the next most recent message in the full message history\n",
        "            next_message_to_add_index -= 1\n",
        "\n",
        "        # Append user input, the length of this is accounted for above\n",
        "        current_context.extend([create_chat_message(\"user\", self.triggering_prompt)])\n",
        "        # Calculate remaining tokens\n",
        "        tokens_remaining = token_limit - current_tokens_used\n",
        "\n",
        "        current_context = construct_prompt(current_context)\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel('gemini-pro', tools=functions)\n",
        "            chat = model.start_chat()\n",
        "            response = chat.send_message(current_context)\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during generation: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        tools = {t.__name__: t for t in self.tools}\n",
        "        while True:\n",
        "            # Send message to AI, get response\n",
        "            response = self.chat_with_ai(token_limit=4000)\n",
        "\n",
        "            if response is not None:\n",
        "              from google.protobuf.json_format import MessageToDict\n",
        "              if \"functionCall\" in MessageToDict(response.candidates[0].content.parts[0]._pb):\n",
        "                  # Update full message history\n",
        "                  function_name = response.candidates[0].content.parts[0].function_call.name\n",
        "\n",
        "                  from google.protobuf.json_format import MessageToDict\n",
        "                  fc = MessageToDict(response.candidates[0].content.parts[0].function_call._pb)\n",
        "\n",
        "                  parsed_output = fc.get('args', {})\n",
        "                  print(\"THiiis: \", parsed_output)\n",
        "                  if \"Error\" in parsed_output:\n",
        "                      error_message = parsed_output[\"Error\"]\n",
        "                      autogpt_logger.info(f\"Error: {error_message}\")\n",
        "                      command_result = f\"Error: {error_message}\"\n",
        "                  else:\n",
        "                      autogpt_logger.info(f\"Function generation requested, function = {function_name}, args = \"\n",
        "                                          f\"{parsed_output}\")\n",
        "                      self.full_message_history.append(\n",
        "                          create_chat_message(\"assistant\", f\"Function generation requested, function = {function_name}, \"\n",
        "                                                          f\"args = {parsed_output}\")\n",
        "                      )\n",
        "                      if function_name == \"finish\":\n",
        "                          response = parsed_output[\"response\"]\n",
        "                          autogpt_logger.info(f\"Responding to user: {response}\")\n",
        "                          return response\n",
        "                      if function_name in tools:\n",
        "                          tool = tools[function_name]\n",
        "                          try:\n",
        "                              autogpt_logger.info(f\"Next function = {function_name}, arguments = {parsed_output}\")\n",
        "                              result = tool(**parsed_output)\n",
        "                              command_result = f\"Executed function {function_name} and returned: {result}\"\n",
        "                          except Exception as e:\n",
        "                              command_result = (\n",
        "                                  f\"Error: {str(e)}, {type(e).__name__}\"\n",
        "                              )\n",
        "                          result_length = count_string_tokens(command_result)\n",
        "\n",
        "                          if result_length + 600 > 4000:\n",
        "                              command_result = f\"Failure: function {function_name} returned too much output. Do not \" \\\n",
        "                                              f\"execute this function again with the same arguments.\"\n",
        "                      else:\n",
        "                          command_result = f\"Unknown function '{function_name}'. Please refer to available functions \" \\\n",
        "                                          f\"defined in functions parameter.\"\n",
        "\n",
        "                  # Append command result to the message history\n",
        "                  self.full_message_history.append(create_chat_message(\"function\", str(command_result), function_name))\n",
        "                  autogpt_logger.info(f\"function: {command_result}\")\n",
        "              else:\n",
        "                  autogpt_logger.info(f\"No function generated, returned: {response.candidates}\")\n",
        "                  self.full_message_history.append(\n",
        "                      create_chat_message(\"assistant\", f\"No function generated, returned: {response.candidates}\")\n",
        "                  )\n",
        "            else:\n",
        "              print(\"No function call in response.\")\n"
      ],
      "metadata": {
        "id": "-lBfDPEbXFYq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "from promptflow import tool\n",
        "from promptflow.connections import AzureOpenAIConnection, OpenAIConnection\n",
        "\n",
        "\n",
        "def autogpt_easy_start(system_prompt: str, user_prompt: str,\n",
        "                       triggering_prompt: str, functions: list, model_or_deployment_name: str):\n",
        "    from wiki_search import search as frisk\n",
        "    from python_repl import python\n",
        "    # from autogpt_class import AutoGPT\n",
        "\n",
        "    full_message_history = []\n",
        "    tools = [\n",
        "        frisk,\n",
        "        python\n",
        "    ]\n",
        "    agent = AutoGPT(\n",
        "        full_message_history=full_message_history,\n",
        "        tools=tools,\n",
        "        system_prompt=system_prompt,\n",
        "        model_or_deployment_name=model_or_deployment_name,\n",
        "        functions=functions,\n",
        "        user_prompt=user_prompt,\n",
        "        triggering_prompt=triggering_prompt\n",
        "    )\n",
        "    result = agent.run()\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "jA5D9jYwYOX0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [my_execution_tools]\n",
        "autogpt_easy_start(system_prompt, user_prompt, triggering_prompt, functions, 'gemini-pro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hYfb8FvEYVh3",
        "outputId": "ca0bb465-c82a-4bf0-811b-5585aa7ae642"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during generation: finish_reason: OTHER\n",
            "index: 0\n",
            "\n",
            "No function call in response.\n",
            "THiiis:  {'entity': 'Lord of the Rings'}\n",
            "[2024-02-20 08:23:19 +0000] autogpt_agent INFO     Function generation requested, function = search, args = {'entity': 'Lord of the Rings'}\n",
            "[2024-02-20 08:23:19 +0000] autogpt_agent INFO     Next function = search, arguments = {'entity': 'Lord of the Rings'}\n",
            "[2024-02-20 08:23:20 +0000] autogpt_agent INFO     function: Executed function search and returned: The Lord of the Rings is an epic[1] high fantasy novel[a] by the English author and scholar J. R. R. Tolkien. Set in Middle-earth, the story began as a sequel to Tolkien's 1937 children's book The Hobbit, but eventually developed into a much larger work. Written in stages between 1937 and 1949, The Lord of the Rings is one of the best-selling books ever written, with over 150 million copies sold.[2]. The title refers to the story's main antagonist,[b] Sauron, the Dark Lord who in an earlier age created the One Ring to rule the other Rings of Power given to Men, Dwarves, and Elves, in his campaign to conquer all of Middle-earth. From homely beginnings in the Shire, a hobbit land reminiscent of the English countryside, the story ranges across Middle-earth, following the quest to destroy the One Ring, seen mainly through the eyes of the hobbits Frodo, Sam, Merry, and Pippin. Aiding Frodo are the Wizard Gandalf, the Men Aragorn and Boromir, the Elf Legolas, and the Dwarf Gimli, who unite in order to rally the Free Peoples of Middle-earth against Sauron's armies and give Frodo a chance to destroy the One Ring in the fire of Mount Doom.. Although often called a trilogy, the work was intended by Tolkien to be one volume in a two-volume set along with The Silmarillion.[3][T 3] For economic reasons, The Lord of the Rings was first published over the course of a year from 29 July 1954 to 20 October 1955 in three volumes rather than one[3][4] under the titles The Fellowship of the Ring, The Two Towers, and The Return of the King; The Silmarillion appeared only after the author's death.\n",
            "THiiis:  {'entity': 'Lord of the Rings'}\n",
            "[2024-02-20 08:23:32 +0000] autogpt_agent INFO     Function generation requested, function = search, args = {'entity': 'Lord of the Rings'}\n",
            "[2024-02-20 08:23:32 +0000] autogpt_agent INFO     Next function = search, arguments = {'entity': 'Lord of the Rings'}\n",
            "[2024-02-20 08:23:33 +0000] autogpt_agent INFO     function: Executed function search and returned: The Lord of the Rings is an epic[1] high fantasy novel[a] by the English author and scholar J. R. R. Tolkien. Set in Middle-earth, the story began as a sequel to Tolkien's 1937 children's book The Hobbit, but eventually developed into a much larger work. Written in stages between 1937 and 1949, The Lord of the Rings is one of the best-selling books ever written, with over 150 million copies sold.[2]. The title refers to the story's main antagonist,[b] Sauron, the Dark Lord who in an earlier age created the One Ring to rule the other Rings of Power given to Men, Dwarves, and Elves, in his campaign to conquer all of Middle-earth. From homely beginnings in the Shire, a hobbit land reminiscent of the English countryside, the story ranges across Middle-earth, following the quest to destroy the One Ring, seen mainly through the eyes of the hobbits Frodo, Sam, Merry, and Pippin. Aiding Frodo are the Wizard Gandalf, the Men Aragorn and Boromir, the Elf Legolas, and the Dwarf Gimli, who unite in order to rally the Free Peoples of Middle-earth against Sauron's armies and give Frodo a chance to destroy the One Ring in the fire of Mount Doom.. Although often called a trilogy, the work was intended by Tolkien to be one volume in a two-volume set along with The Silmarillion.[3][T 3] For economic reasons, The Lord of the Rings was first published over the course of a year from 29 July 1954 to 20 October 1955 in three volumes rather than one[3][4] under the titles The Fellowship of the Ring, The Two Towers, and The Return of the King; The Silmarillion appeared only after the author's death.\n",
            "THiiis:  {'entity': 'Lord of the Rings film trilogy'}\n",
            "[2024-02-20 08:23:40 +0000] autogpt_agent INFO     Function generation requested, function = search, args = {'entity': 'Lord of the Rings film trilogy'}\n",
            "[2024-02-20 08:23:40 +0000] autogpt_agent INFO     Next function = search, arguments = {'entity': 'Lord of the Rings film trilogy'}\n",
            "[2024-02-20 08:23:42 +0000] autogpt_agent INFO     function: Executed function search and returned: The Lord of the Rings is a trilogy of epic fantasy adventure films directed by Peter Jackson, based on the novel The Lord of the Rings by British author J. R. R. Tolkien. The films are subtitled The Fellowship of the Ring (2001), The Two Towers (2002), and The Return of the King (2003). Produced and distributed by New Line Cinema with the co-production of WingNut Films, the films feature an ensemble cast including Elijah Wood, Ian McKellen, Liv Tyler, Viggo Mortensen, Sean Astin, Cate Blanchett, John Rhys-Davies, Christopher Lee, Billy Boyd, Dominic Monaghan, Orlando Bloom, Hugo Weaving, Andy Serkis and Sean Bean.. Set in the fictional world of Middle-earth, the films follow the hobbit Frodo Baggins as he and the Fellowship embark on a quest to destroy the One Ring, to ensure the destruction of its maker, the Dark Lord Sauron. The Fellowship eventually splits up and Frodo continues the quest with his loyal companion Sam and the treacherous Gollum. Meanwhile, Aragorn, heir in exile to the throne of Gondor, along with the elf Legolas, the dwarf Gimli, Merry, Pippin, and the wizard Gandalf, unite to save the Free Peoples of Middle-earth from the forces of Sauron and rally them in the War of the Ring to aid Frodo by distracting Sauron's attention.. The three films were shot simultaneously in Jackson's native New Zealand from 11 October 1999 until 22 December 2000, with pick-up shots done from 2001 to 2003.\n",
            "THiiis:  {'entity': 'Lord of the Rings film trilogy'}\n",
            "[2024-02-20 08:23:46 +0000] autogpt_agent INFO     Function generation requested, function = search, args = {'entity': 'Lord of the Rings film trilogy'}\n",
            "[2024-02-20 08:23:46 +0000] autogpt_agent INFO     Next function = search, arguments = {'entity': 'Lord of the Rings film trilogy'}\n",
            "[2024-02-20 08:23:47 +0000] autogpt_agent INFO     function: Executed function search and returned: The Lord of the Rings is a trilogy of epic fantasy adventure films directed by Peter Jackson, based on the novel The Lord of the Rings by British author J. R. R. Tolkien. The films are subtitled The Fellowship of the Ring (2001), The Two Towers (2002), and The Return of the King (2003). Produced and distributed by New Line Cinema with the co-production of WingNut Films, the films feature an ensemble cast including Elijah Wood, Ian McKellen, Liv Tyler, Viggo Mortensen, Sean Astin, Cate Blanchett, John Rhys-Davies, Christopher Lee, Billy Boyd, Dominic Monaghan, Orlando Bloom, Hugo Weaving, Andy Serkis and Sean Bean.. Set in the fictional world of Middle-earth, the films follow the hobbit Frodo Baggins as he and the Fellowship embark on a quest to destroy the One Ring, to ensure the destruction of its maker, the Dark Lord Sauron. The Fellowship eventually splits up and Frodo continues the quest with his loyal companion Sam and the treacherous Gollum. Meanwhile, Aragorn, heir in exile to the throne of Gondor, along with the elf Legolas, the dwarf Gimli, Merry, Pippin, and the wizard Gandalf, unite to save the Free Peoples of Middle-earth from the forces of Sauron and rally them in the War of the Ring to aid Frodo by distracting Sauron's attention.. The three films were shot simultaneously in Jackson's native New Zealand from 11 October 1999 until 22 December 2000, with pick-up shots done from 2001 to 2003.\n",
            "[2024-02-20 08:23:54 +0000] autogpt_agent INFO     No function generated, returned: [content {\n",
            "  parts {\n",
            "    text: \" Beware\"\n",
            "  }\n",
            "  role: \"model\"\n",
            "}\n",
            "finish_reason: STOP\n",
            "index: 0\n",
            "safety_ratings {\n",
            "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "  probability: NEGLIGIBLE\n",
            "}\n",
            "safety_ratings {\n",
            "  category: HARM_CATEGORY_HATE_SPEECH\n",
            "  probability: NEGLIGIBLE\n",
            "}\n",
            "safety_ratings {\n",
            "  category: HARM_CATEGORY_HARASSMENT\n",
            "  probability: NEGLIGIBLE\n",
            "}\n",
            "safety_ratings {\n",
            "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "  probability: NEGLIGIBLE\n",
            "}\n",
            "]\n",
            "THiiis:  {'entity': \"Peter Jackson's age\"}\n",
            "[2024-02-20 08:23:59 +0000] autogpt_agent INFO     Function generation requested, function = search, args = {'entity': \"Peter Jackson's age\"}\n",
            "[2024-02-20 08:23:59 +0000] autogpt_agent INFO     Next function = search, arguments = {'entity': \"Peter Jackson's age\"}\n",
            "[2024-02-20 08:24:01 +0000] autogpt_agent INFO     function: Executed function search and returned: Could not find Peter Jackson's age. Similar: ['Peter Jackson', 'The Lovely Bones  ', 'Arwen ', 'Presidency of Andrew Jackson', \"Peter Jackson's interpretation of The Lord of the Rings\"].\n",
            "THiiis:  {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:05 +0000] autogpt_agent INFO     Function generation requested, function = , args = {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:05 +0000] autogpt_agent INFO     function: Unknown function ''. Please refer to available functions defined in functions parameter.\n",
            "THiiis:  {}\n",
            "[2024-02-20 08:24:12 +0000] autogpt_agent INFO     Function generation requested, function = , args = {}\n",
            "[2024-02-20 08:24:12 +0000] autogpt_agent INFO     function: Unknown function ''. Please refer to available functions defined in functions parameter.\n",
            "THiiis:  {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:18 +0000] autogpt_agent INFO     Function generation requested, function = , args = {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:18 +0000] autogpt_agent INFO     function: Unknown function ''. Please refer to available functions defined in functions parameter.\n",
            "THiiis:  {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:21 +0000] autogpt_agent INFO     Function generation requested, function = , args = {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:21 +0000] autogpt_agent INFO     function: Unknown function ''. Please refer to available functions defined in functions parameter.\n",
            "THiiis:  {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:29 +0000] autogpt_agent INFO     Function generation requested, function = , args = {'extension': 'default_api'}\n",
            "[2024-02-20 08:24:29 +0000] autogpt_agent INFO     function: Unknown function ''. Please refer to available functions defined in functions parameter.\n",
            "THiiis:  {'response': \"The 'Lord of the Rings' film trilogy, directed by Peter Jackson, is an epic fantasy adventure based on the novel by J.R.R Tolkien. The trilogy was shot in New Zealand from 1999-2000 and consists of three films: 'The Fellowship of the Ring' (2001), 'The Two Towers' (2002), and 'The Return of the King' (2003). The films follow the journey of the hobbit Frodo Baggins and the Fellowship as they quest to destroy the One Ring and defeat the Dark Lord Sauron.\"}\n",
            "[2024-02-20 08:24:34 +0000] autogpt_agent INFO     Function generation requested, function = finish, args = {'response': \"The 'Lord of the Rings' film trilogy, directed by Peter Jackson, is an epic fantasy adventure based on the novel by J.R.R Tolkien. The trilogy was shot in New Zealand from 1999-2000 and consists of three films: 'The Fellowship of the Ring' (2001), 'The Two Towers' (2002), and 'The Return of the King' (2003). The films follow the journey of the hobbit Frodo Baggins and the Fellowship as they quest to destroy the One Ring and defeat the Dark Lord Sauron.\"}\n",
            "[2024-02-20 08:24:34 +0000] autogpt_agent INFO     Responding to user: The 'Lord of the Rings' film trilogy, directed by Peter Jackson, is an epic fantasy adventure based on the novel by J.R.R Tolkien. The trilogy was shot in New Zealand from 1999-2000 and consists of three films: 'The Fellowship of the Ring' (2001), 'The Two Towers' (2002), and 'The Return of the King' (2003). The films follow the journey of the hobbit Frodo Baggins and the Fellowship as they quest to destroy the One Ring and defeat the Dark Lord Sauron.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The 'Lord of the Rings' film trilogy, directed by Peter Jackson, is an epic fantasy adventure based on the novel by J.R.R Tolkien. The trilogy was shot in New Zealand from 1999-2000 and consists of three films: 'The Fellowship of the Ring' (2001), 'The Two Towers' (2002), and 'The Return of the King' (2003). The films follow the journey of the hobbit Frodo Baggins and the Fellowship as they quest to destroy the One Ring and defeat the Dark Lord Sauron.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next"
      ],
      "metadata": {
        "id": "A90EgfpoZzsq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}