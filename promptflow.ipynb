{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcM0Wf74bQu55niO34pJBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treezy254/Data-science/blob/main/promptflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rccxbSdHcVFS",
        "outputId": "b6e7c2d3-f680-4103-91c9-298dee263912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DHS'...\n",
            "remote: Enumerating objects: 1833, done.\u001b[K\n",
            "remote: Counting objects: 100% (609/609), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 1833 (delta 458), reused 519 (delta 387), pack-reused 1224\u001b[K\n",
            "Receiving objects: 100% (1833/1833), 45.69 MiB | 27.85 MiB/s, done.\n",
            "Resolving deltas: 100% (1062/1062), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/treezy254/DHS-LLM-Workshop.git DHS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd DHS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVkGB663co8b",
        "outputId": "211ededb-a442-4aac-9847-95bb82c10d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DHS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ME9z8xdB_d",
        "outputId": "9ec26950-006b-492f-d57b-cde3f514b86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-0nwcqfau\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-0nwcqfau\n",
            "  Resolved https://github.com/huggingface/transformers to commit 58e3d23e97078f361a533b9ec4a6a2de674ea52a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/accelerate (from -r requirements.txt (line 2))\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-pcm0u4e7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-pcm0u4e7\n",
            "  Resolved https://github.com/huggingface/accelerate to commit b3d2111708a480ddae60c6e1fb80f360326a0dc8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft (from -r requirements.txt (line 3))\n",
            "  Cloning https://github.com/huggingface/peft to /tmp/pip-req-build-6kdo1mbm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-6kdo1mbm\n",
            "  Resolved https://github.com/huggingface/peft to commit a1c472f08f39a4b95a228dd436944bc3a75406ea\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/trl (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/trl to /tmp/pip-req-build-8mthg_ru\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl /tmp/pip-req-build-8mthg_ru\n",
            "  Resolved https://github.com/huggingface/trl to commit 685209716915b010098b7e18b05fbad42af864d3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/datatrove.git (from -r requirements.txt (line 5))\n",
            "  Cloning https://github.com/huggingface/datatrove.git to /tmp/pip-req-build-kj7fr9ix\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datatrove.git /tmp/pip-req-build-kj7fr9ix\n",
            "  Resolved https://github.com/huggingface/datatrove.git to commit bd3c89a2cf65320d42593eb4ab7975cbea878143\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth[conda]@ git+https://github.com/unslothai/unsloth.git (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-bncpu8_s/unsloth_fa0db3a9804e4d45a62e71a9a7386ae0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-bncpu8_s/unsloth_fa0db3a9804e4d45a62e71a9a7386ae0\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit e091bca34ad5df406a693685ea576366d79636f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deepspeed (from -r requirements.txt (line 7))\n",
            "  Downloading deepspeed-0.13.1.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyGithub (from -r requirements.txt (line 8))\n",
            "  Downloading PyGithub-2.2.0-py3-none-any.whl (350 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.2/350.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flash-attn (from -r requirements.txt (line 9))\n",
            "  Downloading flash_attn-2.5.3.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.20.3)\n",
            "Collecting evaluate (from -r requirements.txt (line 11))\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 12))\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from -r requirements.txt (line 13))\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 14))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from -r requirements.txt (line 15))\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.15.1)\n",
            "Collecting tiktoken (from -r requirements.txt (line 17))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (3.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.1.99)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (3.8.1)\n",
            "Collecting xformers (from -r requirements.txt (line 24))\n",
            "  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0->-r requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Collecting tyro>=0.5.11 (from trl==0.7.11.dev0->-r requirements.txt (line 4))\n",
            "  Downloading tyro-0.7.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.0 (from datatrove==0.0.1->-r requirements.txt (line 5))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.12.2 (from datatrove==0.0.1->-r requirements.txt (line 5))\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from datatrove==0.0.1->-r requirements.txt (line 5)) (4.7.0)\n",
            "Collecting loguru>=0.7.0 (from datatrove==0.0.1->-r requirements.txt (line 5))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datatrove==0.0.1->-r requirements.txt (line 5))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from -r requirements.txt (line 19))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hjson (from deepspeed->-r requirements.txt (line 7))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed->-r requirements.txt (line 7))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed->-r requirements.txt (line 7)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed->-r requirements.txt (line 7)) (2.6.1)\n",
            "Collecting pynvml (from deepspeed->-r requirements.txt (line 7))\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.4.0 (from PyGithub->-r requirements.txt (line 8))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt[crypto]>=2.4.0 (from PyGithub->-r requirements.txt (line 8))\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub->-r requirements.txt (line 8)) (2.0.7)\n",
            "Collecting Deprecated (from PyGithub->-r requirements.txt (line 8))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 11)) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate->-r requirements.txt (line 11))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting pyarrow>=12.0.0 (from datasets->-r requirements.txt (line 12))\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 12)) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 12)) (3.9.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 15)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 15))\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 15))\n",
            "  Downloading sentry_sdk-1.40.3-py2.py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.8/257.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 15))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 15))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 15)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 15)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 15)) (3.20.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.5.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 18)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 18)) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 21)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 21)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 21)) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 21)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 21)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 21)) (3.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 23)) (1.3.2)\n",
            "Collecting torch>=1.10.0 (from accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fsspec[http]>=2021.05.0 (from evaluate->-r requirements.txt (line 11))\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.1-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers (from -r requirements.txt (line 24))\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting datasets (from -r requirements.txt (line 12))\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 12)) (10.0.1)\n",
            "Collecting dill>=0.3.0 (from datatrove==0.0.1->-r requirements.txt (line 5))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets (from -r requirements.txt (line 12))\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 12)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 12)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 12)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 12)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 15))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub->-r requirements.txt (line 8)) (42.0.2)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0->-r requirements.txt (line 1)) (2024.2.2)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl==0.7.11.dev0->-r requirements.txt (line 4))\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.11.dev0->-r requirements.txt (line 4)) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.11.dev0->-r requirements.txt (line 4))\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 16)) (2.1.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGithub->-r requirements.txt (line 8)) (1.14.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datatrove==0.0.1->-r requirements.txt (line 5))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed->-r requirements.txt (line 7)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed->-r requirements.txt (line 7)) (2.16.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub->-r requirements.txt (line 8)) (2.21)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 15))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 16)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 16)) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.28.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11.dev0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Building wheels for collected packages: transformers, accelerate, peft, trl, datatrove, deepspeed, flash-attn, unsloth\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8458697 sha256=0826d219c2fe6a841fe1ccfd16ae3c0650817bd2b8bc29d4d2c276017c1749e7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c9i5kr8/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.28.0-py3-none-any.whl size=279709 sha256=30ead85d0735de5cdb6075aaeea6af87d1769def35d60b159cab3d847f388e1a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c9i5kr8/wheels/f6/c7/9d/1b8a5ca8353d9307733bc719107acb67acdc95063bba749f26\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.8.2-py3-none-any.whl size=183077 sha256=978ef45253836cdbb26155d8cf0b5a52738ddb4b632e7407d7439615ebebfb9e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c9i5kr8/wheels/4c/16/67/1002a2d4daa822eff130e6d85b90051b75d2ce0d26b9448e4a\n",
            "  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trl: filename=trl-0.7.11.dev0-py3-none-any.whl size=152815 sha256=1f3497751ce9e83dd6050ace95539a87f4564e527e16703c3e2ffd55ddae0d3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c9i5kr8/wheels/6a/aa/56/d64d9ae3521350622f9325fdc3bccb4dd3d3ec1c1d8e917400\n",
            "  Building wheel for datatrove (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datatrove: filename=datatrove-0.0.1-py3-none-any.whl size=16615821 sha256=49a0ff1160db60a0ab35f8a82b890dae3874ee716852e407b589412b2081c06d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c9i5kr8/wheels/8a/74/96/5af76f3e0504a1ed76602ea64ffadeb493297b90d375394cd0\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.13.1-py3-none-any.whl size=1350277 sha256=3e49da30033237a3b0bc53b8c4edb29d252ee8fb1abdbaecd421cf5c6cbf52fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/fb/b5/b159b3500525eca167d8ca6e3a7e224b6075045cac90f47cf7\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.5.3-cp310-cp310-linux_x86_64.whl size=120817842 sha256=26616addbd1356f9cdf3b347bed9dfc7c47bf9e1465b8b3cacbade5069e79555\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/ff/66/7f33fff3f6367fc46a010fd8f32ee4c3958b9b0730e61ec4b2\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2024.2-py3-none-any.whl size=66672 sha256=f04f5c518eaede17c5f859d7076c100004007069e04ebb636549a6d207b1631a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1c9i5kr8/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built transformers accelerate peft trl datatrove deepspeed flash-attn unsloth\n",
            "Installing collected packages: ninja, hjson, unsloth, triton, smmap, shtab, setproctitle, sentry-sdk, pynvml, pyjwt, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, loguru, fsspec, einops, docstring-parser, docker-pycreds, dill, Deprecated, tiktoken, responses, pynacl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, gitdb, tyro, nvidia-cusolver-cu12, GitPython, datatrove, bitsandbytes, wandb, transformers, torch, PyGithub, datasets, xformers, flash-attn, evaluate, deepspeed, accelerate, trl, peft\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 GitPython-3.1.41 PyGithub-2.2.0 accelerate-0.28.0 bitsandbytes-0.42.0 datasets-2.14.4 datatrove-0.0.1 deepspeed-0.13.1 dill-0.3.7 docker-pycreds-0.4.0 docstring-parser-0.15 einops-0.7.0 evaluate-0.4.1 flash-attn-2.5.3 fsspec-2024.2.0 gitdb-4.0.11 hjson-3.1.0 loguru-0.7.2 multiprocess-0.70.15 ninja-1.11.1.1 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 peft-0.8.2 pyjwt-2.8.0 pynacl-1.5.0 pynvml-11.5.0 responses-0.18.0 sentry-sdk-1.40.3 setproctitle-1.3.3 shtab-1.6.5 smmap-5.0.1 tiktoken-0.6.0 torch-2.2.0 transformers-4.38.0.dev0 triton-2.2.0 trl-0.7.11.dev0 tyro-0.7.2 unsloth-2024.2 wandb-0.16.3 xformers-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd personal_copilot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g11uoThUdEmy",
        "outputId": "6b78d038-07ec-4ad4-eef1-486731c3e511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DHS/personal_copilot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd dataset_generation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0T-prZieYdM",
        "outputId": "330f591e-6b6c-4053-9601-70aee5aa52fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DHS/personal_copilot/dataset_generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GH_ACCESS_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "3XuhVjsVfUWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 clone_hf_repos.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N3zx4kkebBt",
        "outputId": "7bb5ed18-ec47-4ad4-e2bf-b75ce82837b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'promptflow_repo/promptflow'...\n",
            "remote: Enumerating objects: 42378, done.\u001b[K\n",
            "remote: Counting objects: 100% (4176/4176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2173/2173), done.\u001b[K\n",
            "remote: Total 42378 (delta 2789), reused 3151 (delta 1969), pack-reused 38202\u001b[K\n",
            "Receiving objects: 100% (42378/42378), 87.46 MiB | 21.79 MiB/s, done.\n",
            "Resolving deltas: 100% (30232/30232), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf examples scripts"
      ],
      "metadata": {
        "id": "d1oS8F-FfnYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VfUMP9PgpNL",
        "outputId": "143cae20-1557-4744-f57e-2eb2734dfd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CODE_OF_CONDUCT.md  \u001b[0m\u001b[01;34mdocs\u001b[0m/    README.md    setup.cfg  SUPPORT.md\n",
            "CONTRIBUTING.md     LICENSE  SECURITY.md  \u001b[01;34msrc\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcUn3Mzyg0M-",
        "outputId": "80a7fca3-32f9-45de-cfd4-e327de96e894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jys3N3rSg84a",
        "outputId": "23fe7bdb-30b2-4627-8be8-412f56ab2196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGcqWm3yiQ3X",
        "outputId": "5a0d2d2c-a038-4011-b38f-3ae15a7c4ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DHS/personal_copilot/dataset_generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 pipeline.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv6AyyeihKu_",
        "outputId": "c558c767-ed14-4bb7-8750-710d208ddc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2024-02-12 09:00:17.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36madd_task_logger\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLaunching pipeline for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36mlog_pipeline\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1m\n",
            "--- 🛠️ PIPELINE 🛠\n",
            "📖 - READER: 👾 PersonalCopilot\n",
            "🔻 - FILTER: 🧑🏽‍💻 Code Filter\n",
            "💽 - WRITER: 🐿 Jsonl\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.cspell.json\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.git/hooks/pre-push.sample\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.github/CODEOWNERS\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.github/workflows/check_enforcer.yml\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.github/workflows/samples_flows_chat_basic_chat.yml\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.github/workflows/samples_flows_standard_autonomous_agent.yml\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.github/workflows/samples_getstarted_quickstartazure.yml\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/.github/workflows/sdk-cli-azure-test.yml\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/SECURITY.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/concepts/design-principles.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/how-to-guides/develop-a-tool/add-a-tool-icon.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/how-to-guides/process-image-in-flow.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/cloud/azureml/run-with-additional-includes.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/contributing/mapping_input_description.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/conditional-flow-with-activate/activate_condition_always_met.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/develop-a-tool/category_and_tags_in_tool_tree.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/develop-a-tool/use_file_path_in_script_tool.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/init-and-test-a-flow/chat.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/quick-start/flow-directory-and-dag-yaml.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/quick-start/vs_code_connection_3.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/vscode_create_connection.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/media/how-to-guides/vscode_start_local_app.png\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/docs/reference/tools-reference/aoai-gpt4-turbo-vision.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow-tools/README.dev.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow-tools/promptflow/tools/yamls/aoai_gpt4v.yaml\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/pf\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_cli/_pf_azure/__init__.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_cli/data/entry_flow/gitignore\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_cli/data/standard_flow/hello.jinja2\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_core/token_provider.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/_orm/orchestrator.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/_service/apis/ui.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/_serving/extension/azureml_extension.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:17.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/_submitter/experiment_orchestrator.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/data/docker/README.md\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/data/tool.schema.json\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_sdk/operations/_experiment_operations.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_trace/_start_trace.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/_utils/multimedia_utils.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/azure/_entities/_workspace_connection_spec.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/azure/_restclient/flow/aio/operations/_bulk_runs_operations.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/azure/_restclient/flow/operations/__init__.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:18.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/azure/_restclient/swagger.json\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m1/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m2/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m3/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m4/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m5/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m6/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m7/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m8/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m9/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m10/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m11/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:19.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m12/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/batch/__init__.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/contracts/run_mode.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/executor/_result.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file promptflow/src/promptflow/promptflow/integrations/__init__.py\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.194\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m85\u001b[0m - \u001b[32m\u001b[1mProcessing done for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m\n",
            "\n",
            "📉📉📉 Stats: Task 0 📉📉📉\n",
            "\n",
            "Total Runtime: 2 seconds\n",
            "\n",
            "📖 - READER: 👾 PersonalCopilot\n",
            "    Runtime: (0.59%) 0 seconds [0.28 milliseconds±1.47 milliseconds/doc]\n",
            "    Stats: {input_files: 47, doc_len: 1008595 [min=6, max=843145, 708509.85±304044/task], documents: 0 [0.00/input_file]}\n",
            "🔻 - FILTER: 🧑🏽‍💻 Code Filter\n",
            "    Runtime: (79.06%) 1 second [37.39 milliseconds±211.43 milliseconds/doc]\n",
            "    Stats: {total: 47, forwarded: 28, doc_len: 1001173 [min=68, max=843145, 713708.82±299090/task], dropped: 19}\n",
            "💽 - WRITER: 🐿 Jsonl\n",
            "    Runtime: (20.34%) 0 seconds [16.15 milliseconds±41.72 milliseconds/doc]\n",
            "    Stats: {XXXXX.jsonl.gz: 28, total: 28, doc_len: 1001173 [min=68, max=843145, 713708.82±299090/task]}\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m13/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m14/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:20.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m15/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:21.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m16/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:21.450\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m114\u001b[0m - \u001b[32m\u001b[1m\n",
            "\n",
            "📉📉📉 Stats: All 16 tasks 📉📉📉\n",
            "\n",
            "Total Runtime: 1 second ± 0 seconds/task\n",
            "\n",
            "📖 - READER: 👾 PersonalCopilot\n",
            "    Runtime: (2.02%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [0.46 milliseconds±2.84 milliseconds/doc]\n",
            "    Stats: {input_files: 746, doc_len: 12629041 [min=6, max=3515669, 1696994.19±1303516/task], documents: 0 [0.00/input_file]}\n",
            "🔻 - FILTER: 🧑🏽‍💻 Code Filter\n",
            "    Runtime: (65.85%) 0 seconds±0 seconds/task, min=0 seconds, max=1 second [14.85 milliseconds±82.17 milliseconds/doc]\n",
            "    Stats: {total: 746, forwarded: 450, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task], dropped: 296}\n",
            "💽 - WRITER: 🐿 Jsonl\n",
            "    Runtime: (32.13%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [12.01 milliseconds±28.55 milliseconds/doc]\n",
            "    Stats: {XXXXX.jsonl.gz: 450, total: 450, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task]}\u001b[0m\n",
            "\n",
            "\n",
            "📉📉📉 Stats 📉📉📉\n",
            "\n",
            "Total Runtime: 1 second ± 0 seconds/task\n",
            "\n",
            "📖 - READER: 👾 PersonalCopilot\n",
            "    Runtime: (2.02%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [0.46 milliseconds±2.84 milliseconds/doc]\n",
            "    Stats: {input_files: 746, doc_len: 12629041 [min=6, max=3515669, 1696994.19±1303516/task], documents: 0 [0.00/input_file]}\n",
            "🔻 - FILTER: 🧑🏽‍💻 Code Filter\n",
            "    Runtime: (65.85%) 0 seconds±0 seconds/task, min=0 seconds, max=1 second [14.85 milliseconds±82.17 milliseconds/doc]\n",
            "    Stats: {total: 746, forwarded: 450, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task], dropped: 296}\n",
            "💽 - WRITER: 🐿 Jsonl\n",
            "    Runtime: (32.13%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [12.01 milliseconds±28.55 milliseconds/doc]\n",
            "    Stats: {XXXXX.jsonl.gz: 450, total: 450, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task]}\n",
            "\u001b[32m2024-02-12 09:00:32.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36madd_task_logger\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLaunching pipeline for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:32.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36mlog_pipeline\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1m\n",
            "--- 🛠️ PIPELINE 🛠\n",
            "📖 - READER: 🐿 Jsonl\n",
            "🫂 - DEDUP: 🎯 MinHash stage 1\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:32.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file 00000.jsonl.gz\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:47.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m1/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m2/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m3/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m4/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m5/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m6/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m7/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m8/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m9/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m10/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:48.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m11/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:49.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m12/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:49.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m13/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:50.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.dedup.minhash\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mSorting buckets...\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:50.793\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m85\u001b[0m - \u001b[32m\u001b[1mProcessing done for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:50.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m\n",
            "\n",
            "📉📉📉 Stats: Task 0 📉📉📉\n",
            "\n",
            "Total Runtime: 18 seconds\n",
            "\n",
            "📖 - READER: 🐿 Jsonl\n",
            "    Runtime: (0.73%) 0 seconds [4.74 milliseconds±13.11 milliseconds/doc]\n",
            "    Stats: {input_files: 1, doc_len: 1001173 [min=68, max=843145, 713708.82±299090/task], documents: 27 [27.00/input_file]}\n",
            "🫂 - DEDUP: 🎯 MinHash stage 1\n",
            "    Runtime: (99.27%) 18 seconds [18 seconds and 48.14 milliseconds±0 milliseconds/doc]\n",
            "    Stats: {total: 28}\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:50.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m14/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:54.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m15/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:54.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m16/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:00:54.503\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m114\u001b[0m - \u001b[32m\u001b[1m\n",
            "\n",
            "📉📉📉 Stats: All 16 tasks 📉📉📉\n",
            "\n",
            "Total Runtime: 16 seconds ± 1 second/task\n",
            "\n",
            "📖 - READER: 🐿 Jsonl\n",
            "    Runtime: (0.28%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [1.61 milliseconds±6.93 milliseconds/doc]\n",
            "    Stats: {input_files: 16, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task], documents: 434 [min=25, max=29, 27.12±1/input_file]}\n",
            "🫂 - DEDUP: 🎯 MinHash stage 1\n",
            "    Runtime: (99.72%) 15 seconds±1 second/task, min=14 seconds, max=20 seconds [15 seconds and 956.15 milliseconds±1 second and 930.78 milliseconds/doc]\n",
            "    Stats: {total: 450}\u001b[0m\n",
            "\n",
            "\n",
            "📉📉📉 Stats 📉📉📉\n",
            "\n",
            "Total Runtime: 16 seconds ± 1 second/task\n",
            "\n",
            "📖 - READER: 🐿 Jsonl\n",
            "    Runtime: (0.28%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [1.61 milliseconds±6.93 milliseconds/doc]\n",
            "    Stats: {input_files: 16, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task], documents: 434 [min=25, max=29, 27.12±1/input_file]}\n",
            "🫂 - DEDUP: 🎯 MinHash stage 1\n",
            "    Runtime: (99.72%) 15 seconds±1 second/task, min=14 seconds, max=20 seconds [15 seconds and 956.15 milliseconds±1 second and 930.78 milliseconds/doc]\n",
            "    Stats: {total: 450}\n",
            "\u001b[32m2024-02-12 09:01:02.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36madd_task_logger\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLaunching pipeline for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:02.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36mlog_pipeline\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1m\n",
            "--- 🛠️ PIPELINE 🛠\n",
            "🫂 - DEDUP: 🎯 MinHash stage 2\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:02.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.dedup.minhash\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m296\u001b[0m - \u001b[1mRunning worker 1/1 on bucket 000. Hash range: [0, 2305843009213693951]\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:02.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.dedup.minhash\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mFinished initializing signatures priority queue.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.050\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m85\u001b[0m - \u001b[32m\u001b[1mProcessing done for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m\n",
            "\n",
            "📉📉📉 Stats: Task 0 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds\n",
            "\n",
            "🫂 - DEDUP: 🎯 MinHash stage 2\n",
            "    Runtime: (100.00%) 0 seconds [86.98 milliseconds±0 milliseconds/doc]\n",
            "    Stats: {total_matches: 28}\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m1/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m2/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m3/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m4/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m5/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m6/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m7/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m8/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m9/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m10/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m11/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m12/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m13/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m14/14 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.707\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m114\u001b[0m - \u001b[32m\u001b[1m\n",
            "\n",
            "📉📉📉 Stats: All 14 tasks 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds ± 0 seconds/task\n",
            "\n",
            "🫂 - DEDUP: 🎯 MinHash stage 2\n",
            "    Runtime: (100.00%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [50.69 milliseconds±23.34 milliseconds/doc]\n",
            "    Stats: {total_matches: 370}\u001b[0m\n",
            "\n",
            "\n",
            "📉📉📉 Stats 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds ± 0 seconds/task\n",
            "\n",
            "🫂 - DEDUP: 🎯 MinHash stage 2\n",
            "    Runtime: (100.00%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [50.69 milliseconds±23.34 milliseconds/doc]\n",
            "    Stats: {total_matches: 370}\n",
            "\u001b[32m2024-02-12 09:01:03.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36madd_task_logger\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLaunching pipeline for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36mlog_pipeline\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1m\n",
            "--- 🛠️ PIPELINE 🛠\n",
            "🫂 - DEDUP: 🎯 MinHash stage 3\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.752\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m85\u001b[0m - \u001b[32m\u001b[1mProcessing done for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m\n",
            "\n",
            "📉📉📉 Stats: Task 0 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds\n",
            "\n",
            "🫂 - DEDUP: 🎯 MinHash stage 3\n",
            "    Runtime: (100.00%) 0 seconds [3.76 milliseconds±0 milliseconds/doc]\n",
            "    Stats: {duplicates: 36, to_remove: 29}\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:03.761\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m114\u001b[0m - \u001b[32m\u001b[1m\n",
            "\n",
            "📉📉📉 Stats: All 1 tasks 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds\n",
            "\n",
            "🫂 - DEDUP: 🎯 MinHash stage 3\n",
            "    Runtime: (100.00%) 0 seconds [3.76 milliseconds±0 milliseconds/doc]\n",
            "    Stats: {duplicates: 36, to_remove: 29}\u001b[0m\n",
            "\n",
            "\n",
            "📉📉📉 Stats 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds\n",
            "\n",
            "🫂 - DEDUP: 🎯 MinHash stage 3\n",
            "    Runtime: (100.00%) 0 seconds [3.76 milliseconds±0 milliseconds/doc]\n",
            "    Stats: {duplicates: 36, to_remove: 29}\n",
            "\u001b[32m2024-02-12 09:01:14.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36madd_task_logger\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mLaunching pipeline for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:14.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.utils.logging\u001b[0m:\u001b[36mlog_pipeline\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1m\n",
            "--- 🛠️ PIPELINE 🛠\n",
            "📖 - READER: 🐿 Jsonl\n",
            "🔢 - TOKENIZER: 📊 Counter\n",
            "🫂 - DEDUP: 🎯 MinHash stage 4\n",
            "💽 - WRITER: 🐿 Jsonl\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:14.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mReading input file 00000.jsonl.gz\u001b[0m\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 18.9MB/s]\n",
            "\u001b[32m2024-02-12 09:01:19.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m1/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:20.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m2/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:20.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m3/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:21.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m4/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:21.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m5/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:21.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m6/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:21.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m7/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:22.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m8/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:22.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m9/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:22.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m10/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:22.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m11/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:22.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m12/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:22.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m13/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:24.645\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m85\u001b[0m - \u001b[32m\u001b[1mProcessing done for rank=0\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:24.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.base\u001b[0m:\u001b[36m_run_for_rank\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1m\n",
            "\n",
            "📉📉📉 Stats: Task 0 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds\n",
            "\n",
            "📖 - READER: 🐿 Jsonl\n",
            "    Runtime: (18.61%) 0 seconds [3.40 milliseconds±10.59 milliseconds/doc]\n",
            "    Stats: {input_files: 1, doc_len: 1001173 [min=68, max=843145, 713708.82±299090/task], documents: 27 [27.00/input_file]}\n",
            "🔢 - TOKENIZER: 📊 Counter\n",
            "    Stats: {tokens: 557493 [min=28, max=491948, 19910.46±92609/doc]}\n",
            "🫂 - DEDUP: 🎯 MinHash stage 4\n",
            "    Runtime: (0.09%) 0 seconds [0.02 milliseconds±0.00 milliseconds/doc]\n",
            "    Stats: {total: 28, forwarded: 28}\n",
            "💽 - WRITER: 🐿 Jsonl\n",
            "    Runtime: (81.31%) 0 seconds [14.88 milliseconds±28.22 milliseconds/doc]\n",
            "    Stats: {XXXXX.jsonl.gz: 28, total: 28, doc_len: 1001173 [min=68, max=843145, 713708.82±299090/task], doc_len_tokens: 557493 [min=28, max=491948, 435279.43±155279/task]}\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:24.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m14/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:26.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m15/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:26.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36m_launch_run_for_rank\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m16/16 tasks completed.\u001b[0m\n",
            "\u001b[32m2024-02-12 09:01:27.151\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdatatrove.executor.local\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m114\u001b[0m - \u001b[32m\u001b[1m\n",
            "\n",
            "📉📉📉 Stats: All 16 tasks 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds ± 0 seconds/task\n",
            "\n",
            "📖 - READER: 🐿 Jsonl\n",
            "    Runtime: (13.37%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [2.52 milliseconds±12.16 milliseconds/doc]\n",
            "    Stats: {input_files: 16, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task], documents: 434 [min=25, max=29, 27.12±1/input_file]}\n",
            "🔢 - TOKENIZER: 📊 Counter\n",
            "    Stats: {tokens: 3191261 [min=6, max=751139, 7091.69±53151/doc]}\n",
            "🫂 - DEDUP: 🎯 MinHash stage 4\n",
            "    Runtime: (5.69%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [1.07 milliseconds±5.87 milliseconds/doc]\n",
            "    Stats: {total: 450, forwarded: 417, dropped: 33}\n",
            "💽 - WRITER: 🐿 Jsonl\n",
            "    Runtime: (80.93%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [16.46 milliseconds±27.77 milliseconds/doc]\n",
            "    Stats: {XXXXX.jsonl.gz: 417, total: 417, doc_len: 7317702 [min=13, max=1767410, 888126.74±784293/task], doc_len_tokens: 3162294 [min=6, max=751139, 408099.94±327694/task]}\u001b[0m\n",
            "\n",
            "\n",
            "📉📉📉 Stats 📉📉📉\n",
            "\n",
            "Total Runtime: 0 seconds ± 0 seconds/task\n",
            "\n",
            "📖 - READER: 🐿 Jsonl\n",
            "    Runtime: (13.37%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [2.52 milliseconds±12.16 milliseconds/doc]\n",
            "    Stats: {input_files: 16, doc_len: 7392722 [min=13, max=1767410, 879527.13±784916/task], documents: 434 [min=25, max=29, 27.12±1/input_file]}\n",
            "🔢 - TOKENIZER: 📊 Counter\n",
            "    Stats: {tokens: 3191261 [min=6, max=751139, 7091.69±53151/doc]}\n",
            "🫂 - DEDUP: 🎯 MinHash stage 4\n",
            "    Runtime: (5.69%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [1.07 milliseconds±5.87 milliseconds/doc]\n",
            "    Stats: {total: 450, forwarded: 417, dropped: 33}\n",
            "💽 - WRITER: 🐿 Jsonl\n",
            "    Runtime: (80.93%) 0 seconds±0 seconds/task, min=0 seconds, max=0 seconds [16.46 milliseconds±27.77 milliseconds/doc]\n",
            "    Stats: {XXXXX.jsonl.gz: 417, total: 417, doc_len: 7317702 [min=13, max=1767410, 888126.74±784293/task], doc_len_tokens: 3162294 [min=6, max=751139, 408099.94±327694/task]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFAdsiCBhTlI",
        "outputId": "de14747f-0c02-47a9-d184-83c5921b8224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 prepare_hf_dataset.py"
      ],
      "metadata": {
        "id": "cZ4mYzOWj_k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "MniczIFxkLsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataframe.csv.gz')"
      ],
      "metadata": {
        "id": "OLT5wgFUlgcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "vkNmxV0nlkNe",
        "outputId": "6e05dabd-9d36-4811-d42c-90e063e25e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  # Run prompt flow in Azure AI\\n\\n:::{admonitio...   \n",
              "1  # Deploy a flow using Kubernetes\\n:::{admoniti...   \n",
              "2  # Using File Path as Tool Input\\n\\nUsers somet...   \n",
              "3  # Alternative LLMs\\n\\nThis section provides tu...   \n",
              "4  # Python\\n\\n## Introduction\\nUsers are empower...   \n",
              "\n",
              "                                                  id  \\\n",
              "0  promptflow/docs/cloud/azureai/quick-start/inde...   \n",
              "1  promptflow/docs/how-to-guides/deploy-a-flow/de...   \n",
              "2  promptflow/docs/how-to-guides/develop-a-tool/u...   \n",
              "3       promptflow/docs/integrations/llms/index.md/0   \n",
              "4  promptflow/docs/reference/tools-reference/pyth...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'file_path': 'promptflow/docs/cloud/azureai/q...  \n",
              "1  {'file_path': 'promptflow/docs/how-to-guides/d...  \n",
              "2  {'file_path': 'promptflow/docs/how-to-guides/d...  \n",
              "3  {'file_path': 'promptflow/docs/integrations/ll...  \n",
              "4  {'file_path': 'promptflow/docs/reference/tools...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d288be7-014f-4030-b7ee-b12955d8d5a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># Run prompt flow in Azure AI\\n\\n:::{admonitio...</td>\n",
              "      <td>promptflow/docs/cloud/azureai/quick-start/inde...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/cloud/azureai/q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td># Deploy a flow using Kubernetes\\n:::{admoniti...</td>\n",
              "      <td>promptflow/docs/how-to-guides/deploy-a-flow/de...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/how-to-guides/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td># Using File Path as Tool Input\\n\\nUsers somet...</td>\n",
              "      <td>promptflow/docs/how-to-guides/develop-a-tool/u...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/how-to-guides/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># Alternative LLMs\\n\\nThis section provides tu...</td>\n",
              "      <td>promptflow/docs/integrations/llms/index.md/0</td>\n",
              "      <td>{'file_path': 'promptflow/docs/integrations/ll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td># Python\\n\\n## Introduction\\nUsers are empower...</td>\n",
              "      <td>promptflow/docs/reference/tools-reference/pyth...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/reference/tools...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d288be7-014f-4030-b7ee-b12955d8d5a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d288be7-014f-4030-b7ee-b12955d8d5a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d288be7-014f-4030-b7ee-b12955d8d5a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-597fbba1-5588-456f-a25d-74615ac5db5f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-597fbba1-5588-456f-a25d-74615ac5db5f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-597fbba1-5588-456f-a25d-74615ac5db5f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'text': 'content', 'id': 'filepath'})\n",
        "df = df[['filepath', 'content', 'metadata']]"
      ],
      "metadata": {
        "id": "uvYf74V0lmc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "qwl6C3Pyl_8-",
        "outputId": "27a3ec2d-a881-478b-de6e-97d32e255a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            filepath  \\\n",
              "0  promptflow/docs/cloud/azureai/quick-start/inde...   \n",
              "1  promptflow/docs/how-to-guides/deploy-a-flow/de...   \n",
              "2  promptflow/docs/how-to-guides/develop-a-tool/u...   \n",
              "3       promptflow/docs/integrations/llms/index.md/0   \n",
              "4  promptflow/docs/reference/tools-reference/pyth...   \n",
              "\n",
              "                                             content  \\\n",
              "0  # Run prompt flow in Azure AI\\n\\n:::{admonitio...   \n",
              "1  # Deploy a flow using Kubernetes\\n:::{admoniti...   \n",
              "2  # Using File Path as Tool Input\\n\\nUsers somet...   \n",
              "3  # Alternative LLMs\\n\\nThis section provides tu...   \n",
              "4  # Python\\n\\n## Introduction\\nUsers are empower...   \n",
              "\n",
              "                                            metadata  \n",
              "0  {'file_path': 'promptflow/docs/cloud/azureai/q...  \n",
              "1  {'file_path': 'promptflow/docs/how-to-guides/d...  \n",
              "2  {'file_path': 'promptflow/docs/how-to-guides/d...  \n",
              "3  {'file_path': 'promptflow/docs/integrations/ll...  \n",
              "4  {'file_path': 'promptflow/docs/reference/tools...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d82fd778-ed3f-4336-a67d-43575b4cd10a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>content</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>promptflow/docs/cloud/azureai/quick-start/inde...</td>\n",
              "      <td># Run prompt flow in Azure AI\\n\\n:::{admonitio...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/cloud/azureai/q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>promptflow/docs/how-to-guides/deploy-a-flow/de...</td>\n",
              "      <td># Deploy a flow using Kubernetes\\n:::{admoniti...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/how-to-guides/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>promptflow/docs/how-to-guides/develop-a-tool/u...</td>\n",
              "      <td># Using File Path as Tool Input\\n\\nUsers somet...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/how-to-guides/d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>promptflow/docs/integrations/llms/index.md/0</td>\n",
              "      <td># Alternative LLMs\\n\\nThis section provides tu...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/integrations/ll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>promptflow/docs/reference/tools-reference/pyth...</td>\n",
              "      <td># Python\\n\\n## Introduction\\nUsers are empower...</td>\n",
              "      <td>{'file_path': 'promptflow/docs/reference/tools...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d82fd778-ed3f-4336-a67d-43575b4cd10a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d82fd778-ed3f-4336-a67d-43575b4cd10a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d82fd778-ed3f-4336-a67d-43575b4cd10a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bc547cd7-06c0-441d-abf2-ef4b153860bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc547cd7-06c0-441d-abf2-ef4b153860bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bc547cd7-06c0-441d-abf2-ef4b153860bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2rlajlVm0Lt",
        "outputId": "886f7eba-d7a8-43ba-e430-3cf6357e6c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Installing collected packages: reportlab\n",
            "Successfully installed reportlab-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import re"
      ],
      "metadata": {
        "id": "43BokQsGmBUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_filename = \"dataframe_to_pdf.pdf\"\n",
        "doc = SimpleDocTemplate(pdf_filename, pagesize=letter)\n",
        "styles = getSampleStyleSheet()\n",
        "style_paragraph = styles[\"Normal\"]\n",
        "\n",
        "# Iterate over each row in the DataFrame and add it as a paragraph in the PDF\n",
        "for _, row in df.iterrows():\n",
        "    content = row['content']\n",
        "    filepath = row['filepath']\n",
        "\n",
        "    # Remove HTML-like tags from the content\n",
        "    content = re.sub(r'<[^>]*>', '', content)\n",
        "\n",
        "    content_paragraph = Paragraph(f\"Content: {content}<br/>Filepath: {filepath}\", style_paragraph)\n",
        "    doc.build([content_paragraph, Spacer(1, 24)])  # Add a spacer for page break\n",
        "\n"
      ],
      "metadata": {
        "id": "HBWc8ahNmsyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import re\n",
        "\n",
        "# Create PDF\n",
        "pdf_filename = \"promptflow.pdf\"\n",
        "doc = SimpleDocTemplate(pdf_filename, pagesize=letter)\n",
        "styles = getSampleStyleSheet()\n",
        "style_paragraph = styles[\"Normal\"]\n",
        "\n",
        "# Create a list to store paragraphs\n",
        "paragraphs = []\n",
        "\n",
        "# Iterate over each row in the DataFrame and add it as a paragraph in the list\n",
        "for _, row in df.iterrows():\n",
        "    filepath = row['filepath']\n",
        "    content = row['content']\n",
        "\n",
        "    # Remove HTML-like tags from the content\n",
        "    content = re.sub(r'<[^>]*>', '', content)\n",
        "\n",
        "    # Create a paragraph with content and filepath\n",
        "    content_paragraph = Paragraph(f\"Content: {content}<br/>Filepath: {filepath}\", style_paragraph)\n",
        "\n",
        "    # Add the paragraph to the list\n",
        "    paragraphs.append(content_paragraph)\n",
        "\n",
        "# Add the list of paragraphs to the PDF\n",
        "doc.build(paragraphs)\n"
      ],
      "metadata": {
        "id": "ShEeU4jFnF4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle\n",
        "from reportlab.lib import colors\n",
        "\n",
        "\n",
        "\n",
        "# Create PDF\n",
        "pdf_filename = \"dataframe_to_pdf.pdf\"\n",
        "doc = SimpleDocTemplate(pdf_filename, pagesize=letter)\n",
        "\n",
        "# Adjust cell width based on content length\n",
        "column_widths = [len(max(df[column], key=len)) * 7 for column in df.columns]\n",
        "\n",
        "# Create table data\n",
        "table_data = [df.columns.tolist()] + df.values.tolist()\n",
        "\n",
        "# Create table with adjusted column widths\n",
        "table = Table(table_data, colWidths=column_widths)\n",
        "\n",
        "# Add style to the table\n",
        "style = TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
        "                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
        "                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
        "                    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
        "                    ('GRID', (0, 0), (-1, -1), 1, colors.black)])\n",
        "\n",
        "table.setStyle(style)\n",
        "\n",
        "# Add table to the PDF\n",
        "doc.build([table])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "4uewajBonIAb",
        "outputId": "cc9c726f-bb24-45f7-b42a-aeedb3546516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LayoutError",
          "evalue": "Flowable <Table@0x7A0DECB65F90 417 rows x 3 cols(tallest row 541926)> with cell(0,0) containing\n'promptflow/docs/cloud/azureai/quick-start/index.md/0'(12374075 x 2333298), tallest cell 541926.0 points,  too large on page 2 in frame 'normal'(456.0 x 636.0*) of template 'Later'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLayoutError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-bb1e69ae105f>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Add table to the PDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reportlab/platypus/doctemplate.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, flowables, onFirstPage, onLaterPages, canvasmaker)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0monLaterPages\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_doNothing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'onLaterPages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpageTemplates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeforeDrawPage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monLaterPages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mBaseDocTemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflowables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvasmaker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcanvasmaker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprogressCB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reportlab/platypus/doctemplate.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, flowables, filename, canvasmaker)\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflowables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_flowable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflowables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m                     \u001b[0mhandled\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reportlab/platypus/doctemplate.py\u001b[0m in \u001b[0;36mhandle_flowable\u001b[0;34m(self, flowables)\u001b[0m\n\u001b[1;32m    959\u001b[0m                                         self.frame._aSpaceString(), self.pageTemplate.id)\n\u001b[1;32m    960\u001b[0m                         \u001b[0;31m#leave to keep apart from the raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mLayoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m                     \u001b[0;31m# this ought to be cleared when they are finally drawn!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_postponed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLayoutError\u001b[0m: Flowable <Table@0x7A0DECB65F90 417 rows x 3 cols(tallest row 541926)> with cell(0,0) containing\n'promptflow/docs/cloud/azureai/quick-start/index.md/0'(12374075 x 2333298), tallest cell 541926.0 points,  too large on page 2 in frame 'normal'(456.0 x 636.0*) of template 'Later'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Buw-rpf5ndA4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}